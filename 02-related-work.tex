Graph processing frameworks are software systems designed to efficiently analyze and manipulate graph-structured data, facilitating tasks such as traversal, analytics, and algorithm implementation on various computational architectures. Ligra \cite{shun2013ligra} is a lightweight framework designed for shared-memory parallel/multicore machines, simplifying the development of graph traversal algorithms with two simple routines for edge and vertex mapping. The Galois system \cite{nguyen2013lightweight} advocates for a general-purpose infrastructure supporting fine-grain tasks, speculative execution, and application-specific task scheduling control. Gunrock \cite{wang2016gunrock} tackles irregular data access and control flow issues on GPUs by introducing a data-centric abstraction focused on vertex or edge frontier operations, and enables rapid development of new graph primitives with minimal GPU programming knowledge. Hornet \cite{busato2018hornet} provides a scalable GPU implementation without requiring data reallocation during evolution, targeting dynamic data problems. While frameworks such as these have demonstrated efficient computation on billion-scale graphs, many of them persist with sequential I/O.

Hornet \cite{busato2018hornet} reads a graph in the Matrix Market (MTX) format using the stream operator on \texttt{ifstream}, and then converts it to CSR using \texttt{COOtoCSR()} (in the \texttt{graph::GraphBase::read()} function). The \texttt{COOtoCSR()} function then calculates the out-degrees of each vertex and computes the prefix sum (using \texttt{std::partial\_sum()}) to determine the offsets of outgoing edges in the CSR representation, fills in the CSR arrays ($\_out\_edges$ and $\_out\_offsets$) based on the sorted or randomized COO edges, and if the graph is directed, it also calculates the in-degrees and fills in the corresponding arrays ($\_in\_edges$ and $\_in\_offsets$). In Gunrock \cite{wang2016gunrock}, the \texttt{io::matrix\_ma} \texttt{rket\_t::load()} function handles reading of graphs in the MTX format. It uses \texttt{fscanf()} to read the entries from the input file into three separate \texttt{vector}s, which are then passed to the \texttt{format::csr} \texttt{\_t::from\_coo()} function to generate a CSR. In GraphBLAST \cite{yang2022graphblast}, the \texttt{readMtx()} function is used to read graphs in the MTX format. It uses \texttt{fscanf()} to read tuples/entries, and pushes then to a \texttt{vector}. It then removes self-loops, and does a custom sort of the entries. The GAP Benchmark Suite \cite{beamer2015gap} uses \texttt{ifstream} with \texttt{getline()} and stream operator to read into COO. In each of these frameworks, all of the operations are performed sequentially.

Incorporating Memory-Mapped I/O holds promise for improving graph loading efficiency of frameworks. A number of research studies have worked on optimizing the performance of memory mapped IO. The approaches include using a lightweight userspace memory service \cite{li2019userland}, huge pages \cite{malliotakis2021hugemap}, and asynchronous techniques \cite{imamura2019poster}. A\ignore{large} number of works have optimized memory mapped IO for fast low-latency storage devices \cite{song2012low, song2016efficient, papagiannis2020optimizing, papagiannis2021memory, alverti2022daxvm, leis2023virtual}. Essen et al. \cite{van2015di} and Feng et al. \cite{feng2023tricache} focus on enabling programs to efficiently process out-of-core datasets through memory mapping.

In NetworKit \cite{staudt2016networkit}, the \texttt{MatrixMarketReader::read()} function handles reading of graphs in the MTX format. The function uses \texttt{istream} to read each entry using the stream operator, which is then pushed to a \texttt{vector}. This vector is then passed to \texttt{CSRMatrix}, which sequentially adds the entries in the vector to a CSR. Since the offsets array of the CSR must start with a zero, it puts a zero at the end and rotates the offsets array. We now discuss the \texttt{EdgeListReader::re} \texttt{ad()} function, which handles reading of graphs in COO/Edgelist format, and returns a \texttt{Graph}. It maps the file to memory with the \texttt{MemoryMappedFile} class, reads source/target vertex IDs with \texttt{strtol()}, edge weights with \texttt{strtod()}, conditionally adjusts the number of nodes at each step with \texttt{graph.addNodes()}, and conditionally adds an edge to the graph with \texttt{graph.addEdge()}. However, the function sequential, and adding each edge to the graph is expensive, i.e., $O(D)$ (where $D$ is the average degree). Further, the \texttt{MemoryMappedFile} class does not use \texttt{madvice()} to recommend a memory access pattern to the OS.\ignore{The call to \texttt{mmap()} uses \texttt{PROT\_READ} and \texttt{MAP\_PRIVATE}.}

Gabert and Çatalyürek \cite{gabert2021pigo} observe that even on high-performance shared-memory graph systems running billion-scale graphs, reading the graph from file systems takes multiple orders of magnitude longer than running the computational kernel. To address this issue, they propose PIGO, a high-performance parallel graph loader that brings I/O improvements to graph systems.

In the \texttt{COO::read\_mm\_()} function, PIGO handles the reading of graphs in MTX format. It employs the \texttt{O\_DIRECT} flag in Linux to open the file and maps the entire file to memory using \texttt{mmap()}, with \texttt{MAP\_SHARED} and \texttt{MAP\_NORESERVE} flags. It additionally utilizes \texttt{madvice()} with the \texttt{MADV\_WILLNEED} flag. PIGO however disregards MTX attributes. The authors of PIGO plan to fix this in the future. It then reads the first line of the file, containing information about rows, columns, and the number of edges. For integer reading, it navigates the file reader pointer to the next digit, reads an integer (using custom code), and then moves to the end-of-line. PIGO then proceeds to read the Edgelist with the \texttt{COO::read\_el\_()} function. Here, the split is split into equally sized parts for each thread to process. Each thread then adjusts the boundaries of its part, in order to eliminate overlapping entries. Now, in \texttt{COO::read\_el\_()}, a two pass approach is employed. In the first pass, each thread simply counts newlines in the part of file assigned to it and performs a prefix sum to determine write addresses for each thread into the Edgelist. In the second pass, PIGO iterates through the input file again, but this time, parsing and populating the source/target vertex IDs into the Edgelist. Memory allocation for \texttt{src}, \texttt{dst}, and \texttt{weights} is performed separately using \texttt{std::vector::resize()}.

After reading the input graph as an Edgelist, PIGO can convert it to the CSR format using the \texttt{convert\_coo\_()} function, or the \texttt{read\_graph\_()} function if the file type is specified as \texttt{GRAPH}. In \texttt{convert\_coo\_()}, PIGO allocates space for CSR and employs a multi-pass algorithm. Initially, it computes the each vertex's degree in a shared global array, and then transforms the degrees into the offsets array of the CSR using an exclusive sum algorithm. Then, treating the computed degrees as remaining vertices, Finally, PIGO copies over the edges into the targets array of the CSR. It does this with static loop scheduling, and atomic operations.\ignore{Temporary arrays are subsequently freed.}

\ignore{cuDF employs a GPU-accelerated parsing algorithm to efficiently read and interpret the CSV data within each chunk. This algorithm is optimized for GPU architecture and takes advantage of parallelism to process data quickly.}
